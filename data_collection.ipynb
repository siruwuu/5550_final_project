{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"5550 API Parsing North America\"\n",
    "author: \"Siru Wu\"\n",
    "format: \n",
    "    html: \n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cdsapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcdsapi\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cdsapi'"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import netCDF4\n",
    "import h5netcdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/opt/python-env/bin:/home/siruwww/.vscode-server/bin/b58957e67ee1e712cebf466b995adf4c5307b2bd/bin/remote-cli:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files/dotnet/:/mnt/c/Program Files/Microsoft SQL Server/150/Tools/Binn/:/mnt/c/Program Files (x86)/Windows Kits/10/Windows Performance Toolkit/:/mnt/c/Users/Administrator/AppData/Local/Programs/Quarto/bin:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files/dotnet/:/mnt/d/Scripts/:/mnt/d/:/mnt/c/Users/Administrator/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/Administrator/AppData/Local/Programs/Microsoft VS Code/bin:/snap/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cdsapi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建客户端\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mcdsapi\u001b[49m\u001b[38;5;241m.\u001b[39mClient()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 数据集名称\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreanalysis-era5-land\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cdsapi' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建客户端\n",
    "client = cdsapi.Client()\n",
    "\n",
    "# 数据集名称\n",
    "dataset = \"reanalysis-era5-land\"\n",
    "\n",
    "# 请求的变量\n",
    "variables = [\n",
    "    \"total_precipitation\",          # 降水\n",
    "]\n",
    "\n",
    "# 北美范围\n",
    "north_america_extent = {\n",
    "    \"area\": [85, 190, 10, 310],  # 格式：[北纬, 西经, 南纬, 东经]\n",
    "}\n",
    "\n",
    "# 时间分辨率（6小时）\n",
    "time_intervals = [\n",
    "    \"00:00\", \"12:00\"\n",
    "]\n",
    "\n",
    "# 下载 2024 年 1 到 11 月的数据\n",
    "for month in range(1, 12):\n",
    "    print(f\"Downloading data for month {month:02d}...\")\n",
    "\n",
    "    # 请求参数\n",
    "    request = {\n",
    "        \"format\": \"netcdf\",\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": variables,\n",
    "        \"year\": \"2024\",\n",
    "        \"month\": f\"{month:02d}\",\n",
    "        \"day\": [f\"{day:02d}\" for day in range(1, 32)],  # 天数\n",
    "        \"time\": time_intervals,\n",
    "        **north_america_extent,  # 添加地理范围\n",
    "    }\n",
    "\n",
    "    # 输出文件路径\n",
    "    output_filename = f\"month_data/era5_2024_month_{month:02d}_north_america.nc\"\n",
    "\n",
    "    # 执行抓取\n",
    "    client.retrieve(dataset, request, output_filename)\n",
    "    print(f\"Data for month {month:02d} saved to {output_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"latitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
      "/tmp/ipykernel_1985024/3066542303.py:9: UserWarning: The specified chunks separate the stored chunks along dimension \"longitude\" starting at index 100. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5GB\n",
      "Dimensions:     (valid_time: 1301, latitude: 751, longitude: 1201)\n",
      "Coordinates:\n",
      "    number      int64 8B 0\n",
      "  * valid_time  (valid_time) datetime64[ns] 10kB 2024-01-01 ... 2024-11-21\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 21kB dask.array<chunksize=(124,), meta=np.ndarray>\n",
      "Data variables:\n",
      "    tp          (valid_time, latitude, longitude) float32 5GB dask.array<chunksize=(31, 100, 100), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-11-26T05:23 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "Combined dataset saved to combined_precipitation_data_2024.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "data_directory = \"month_data\"\n",
    "file_paths = sorted([os.path.join(data_directory, f) for f in os.listdir(data_directory) if f.endswith(\".nc\")])\n",
    "\n",
    "# 使用 dask 进行分块加载\n",
    "datasets = [xr.open_dataset(file_path, engine=\"netcdf4\", chunks={\"latitude\": 100, \"longitude\": 100}) for file_path in file_paths]\n",
    "\n",
    "# 沿时间维度 (valid_time) 拼接\n",
    "combined_ds = xr.concat(datasets, dim=\"valid_time\")\n",
    "\n",
    "# 检查合并结果\n",
    "print(combined_ds)\n",
    "\n",
    "# 保存合并结果到 NetCDF 文件（启用压缩）\n",
    "output_file = \"combined_precipitation_data_2024.nc\"\n",
    "combined_ds.to_netcdf(output_file, encoding={\"tp\": {\"zlib\": True, \"complevel\": 5}})\n",
    "print(f\"Combined dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 5GB\n",
      "Dimensions:     (valid_time: 1301, latitude: 751, longitude: 1201)\n",
      "Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 10kB 2024-01-01 ... 2024-11-21\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 21kB ...\n",
      "Data variables:\n",
      "    tp          (valid_time, latitude, longitude) float32 5GB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-11-26T05:23 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "file_path = \"combined_precipitation_data_2024.nc\"\n",
    "ds = xr.open_dataset(file_path, engine=\"netcdf4\")\n",
    "\n",
    "# 打印数据集的结构\n",
    "print(ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
