{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"5550 API Parsing North America\"\n",
    "author: \"Siru Wu\"\n",
    "format: \n",
    "    html: \n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using API to Parse the ERA5 Reanalysis Data from CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:07:54,248 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2024-11-24 22:07:54,248 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2024-11-24 22:07:54,249 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2024-11-24 22:07:54,249 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for month 01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:07:54,909 INFO Request ID is 167a5361-2e12-4ef8-9534-e4aed6ac501c\n",
      "2024-11-24 22:07:55,121 INFO status has been updated to accepted\n",
      "2024-11-24 22:07:56,361 INFO status has been updated to running\n",
      "2024-11-24 22:10:59,965 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 01 saved to era5_2024_month_01_north_america.nc.\n",
      "Downloading data for month 02...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:11:42,509 INFO Request ID is da32d82e-8373-49c5-9439-2925034eb103\n",
      "2024-11-24 22:11:42,762 INFO status has been updated to accepted\n",
      "2024-11-24 22:11:45,816 INFO status has been updated to running\n",
      "2024-11-24 22:14:37,105 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 02 saved to era5_2024_month_02_north_america.nc.\n",
      "Downloading data for month 03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:14:56,646 INFO Request ID is 7b8d0a7d-e486-4e8d-b0e9-c933beff168c\n",
      "2024-11-24 22:14:56,807 INFO status has been updated to accepted\n",
      "2024-11-24 22:14:59,645 INFO status has been updated to running\n",
      "2024-11-24 22:19:20,999 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 03 saved to era5_2024_month_03_north_america.nc.\n",
      "Downloading data for month 04...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:22:19,364 INFO Request ID is e14d5bf7-7f04-43c1-bb25-e2b48d927ddf\n",
      "2024-11-24 22:22:19,570 INFO status has been updated to accepted\n",
      "2024-11-24 22:22:22,495 INFO status has been updated to running\n",
      "2024-11-24 22:26:40,444 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 04 saved to era5_2024_month_04_north_america.nc.\n",
      "Downloading data for month 05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:28:32,104 INFO Request ID is 1e71da0b-81a4-46fb-89bf-663a43115aaf\n",
      "2024-11-24 22:28:32,452 INFO status has been updated to accepted\n",
      "2024-11-24 22:28:41,706 INFO status has been updated to running\n",
      "2024-11-24 22:32:53,851 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 05 saved to era5_2024_month_05_north_america.nc.\n",
      "Downloading data for month 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:33:19,695 INFO Request ID is 0d110543-48f3-49b2-a157-6fbb6e0e470d\n",
      "2024-11-24 22:33:19,847 INFO status has been updated to accepted\n",
      "2024-11-24 22:33:22,667 INFO status has been updated to running\n",
      "2024-11-24 22:36:16,274 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 06 saved to era5_2024_month_06_north_america.nc.\n",
      "Downloading data for month 07...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:36:41,324 INFO Request ID is 039481d0-e55c-4bac-9a08-b34163bde167\n",
      "2024-11-24 22:36:41,489 INFO status has been updated to accepted\n",
      "2024-11-24 22:36:44,301 INFO status has been updated to running\n",
      "2024-11-24 22:41:02,794 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 07 saved to era5_2024_month_07_north_america.nc.\n",
      "Downloading data for month 08...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:43:07,510 INFO Request ID is 07e22f29-c05f-47be-8e36-1ef66d8adea3\n",
      "2024-11-24 22:43:07,665 INFO status has been updated to accepted\n",
      "2024-11-24 22:43:13,059 INFO status has been updated to running\n",
      "2024-11-24 22:47:28,219 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 08 saved to era5_2024_month_08_north_america.nc.\n",
      "Downloading data for month 09...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:47:49,589 INFO Request ID is 82a7173d-b362-4919-9951-03d31238d869\n",
      "2024-11-24 22:47:49,716 INFO status has been updated to accepted\n",
      "2024-11-24 22:47:52,538 INFO status has been updated to running\n",
      "2024-11-24 22:54:10,636 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 09 saved to era5_2024_month_09_north_america.nc.\n",
      "Downloading data for month 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:56:05,472 INFO Request ID is 410ff86a-aeee-44b5-bd5b-66e4c5e7a3da\n",
      "2024-11-24 22:56:05,624 INFO status has been updated to accepted\n",
      "2024-11-24 22:56:11,257 INFO status has been updated to running\n",
      "2024-11-24 23:00:27,428 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 10 saved to era5_2024_month_10_north_america.nc.\n",
      "Downloading data for month 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 23:01:38,949 INFO Request ID is c724c912-4670-43ba-998a-edba382eac35\n",
      "2024-11-24 23:01:39,128 INFO status has been updated to accepted\n",
      "2024-11-24 23:01:44,337 INFO status has been updated to running\n",
      "2024-11-24 23:06:00,631 INFO status has been updated to successful\n",
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 11 saved to era5_2024_month_11_north_america.nc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "# 创建客户端\n",
    "client = cdsapi.Client()\n",
    "\n",
    "# 数据集名称\n",
    "dataset = \"reanalysis-era5-land\"\n",
    "\n",
    "# 请求的变量\n",
    "variables = [\n",
    "    \"total_precipitation\",          # 降水\n",
    "    \"2m_temperature\",               # 温度\n",
    "    \"10m_u_component_of_wind\",      # 风场\n",
    "    \"surface_pressure\",             # 气压\n",
    "    \"surface_net_solar_radiation\"   # 辐射\n",
    "]\n",
    "\n",
    "# 北美范围\n",
    "north_america_extent = {\n",
    "    \"area\": [85, 190, 10, 310],  # 格式：[北纬, 西经, 南纬, 东经]\n",
    "}\n",
    "\n",
    "# 时间分辨率（6小时）\n",
    "time_intervals = [\n",
    "    \"00:00\", \"06:00\", \"12:00\", \"18:00\"\n",
    "]\n",
    "\n",
    "# 下载 2024 年 1 到 11 月的数据\n",
    "for month in range(1, 12):\n",
    "    print(f\"Downloading data for month {month:02d}...\")\n",
    "\n",
    "    # 请求参数\n",
    "    request = {\n",
    "        \"format\": \"netcdf\",\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": variables,\n",
    "        \"year\": \"2024\",\n",
    "        \"month\": f\"{month:02d}\",\n",
    "        \"day\": [f\"{day:02d}\" for day in range(1, 32)],  # 天数\n",
    "        \"time\": time_intervals,\n",
    "        **north_america_extent,  # 添加地理范围\n",
    "    }\n",
    "\n",
    "    # 输出文件路径\n",
    "    output_filename = f\"era5_2024_month_{month:02d}_north_america.nc\"\n",
    "\n",
    "    # 执行抓取\n",
    "    client.retrieve(dataset, request, output_filename)\n",
    "    print(f\"Data for month {month:02d} saved to {output_filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the nc file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch merge...\n",
      "Merging batch 1 with files: ['Data/era5_2024_month_01_north_america.nc', 'Data/era5_2024_month_02_north_america.nc', 'Data/era5_2024_month_03_north_america.nc']\n",
      "Batch 1 saved to Merged_Batches/batch_1.nc\n",
      "Merging batch 2 with files: ['Data/era5_2024_month_04_north_america.nc', 'Data/era5_2024_month_05_north_america.nc', 'Data/era5_2024_month_06_north_america.nc']\n",
      "Batch 2 saved to Merged_Batches/batch_2.nc\n",
      "Merging batch 3 with files: ['Data/era5_2024_month_07_north_america.nc', 'Data/era5_2024_month_08_north_america.nc', 'Data/era5_2024_month_09_north_america.nc']\n",
      "Batch 3 saved to Merged_Batches/batch_3.nc\n",
      "Merging batch 4 with files: ['Data/era5_2024_month_10_north_america.nc', 'Data/era5_2024_month_11_north_america.nc']\n",
      "Batch 4 saved to Merged_Batches/batch_4.nc\n",
      "All batches have been successfully merged and saved.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "# 设置数据文件夹和输出文件夹路径\n",
    "data_directory = \"Data\"  # 存放原始 .nc 文件的目录\n",
    "output_directory = \"Merged_Batches\"  # 存放分批次合并后的文件\n",
    "\n",
    "# 创建输出文件夹（如果不存在）\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# 获取所有 .nc 文件的路径\n",
    "file_paths = sorted([os.path.join(data_directory, f) for f in os.listdir(data_directory) if f.endswith(\".nc\")])\n",
    "\n",
    "# 设置批次大小（例如每批合并 3 个文件）\n",
    "batch_size = 3\n",
    "\n",
    "# 分批合并文件\n",
    "print(\"Starting batch merge...\")\n",
    "for batch_idx, i in enumerate(range(0, len(file_paths), batch_size)):\n",
    "    # 获取当前批次的文件\n",
    "    batch_files = file_paths[i:i + batch_size]\n",
    "    print(f\"Merging batch {batch_idx + 1} with files: {batch_files}\")\n",
    "\n",
    "    # 打开并合并当前批次的文件\n",
    "    batch_ds = xr.open_mfdataset(batch_files, combine=\"by_coords\")\n",
    "\n",
    "    # 输出文件名\n",
    "    batch_output_file = os.path.join(output_directory, f\"batch_{batch_idx + 1}.nc\")\n",
    "    batch_ds.to_netcdf(batch_output_file)\n",
    "    print(f\"Batch {batch_idx + 1} saved to {batch_output_file}\")\n",
    "\n",
    "# 输出完成信息\n",
    "print(\"All batches have been successfully merged and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: Merged_Batches/batch_1.nc\n",
      "Variables: ['tp', 't2m', 'u10', 'sp', 'ssr']\n",
      "Dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 364, 'latitude': 751, 'longitude': 1201})\n",
      "Coordinates: Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 3kB 2024-01-01 ... 2024-03-31T18:...\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 6kB ...\n",
      "Time range: 2024-01-01T00:00:00.000000000 to 2024-03-31T18:00:00.000000000\n",
      "File check passed.\n",
      "\n",
      "Checking file: Merged_Batches/batch_2.nc\n",
      "Variables: ['tp', 't2m', 'u10', 'sp', 'ssr']\n",
      "Dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 364, 'latitude': 751, 'longitude': 1201})\n",
      "Coordinates: Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 3kB 2024-04-01 ... 2024-06-30T18:...\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 6kB ...\n",
      "Time range: 2024-04-01T00:00:00.000000000 to 2024-06-30T18:00:00.000000000\n",
      "File check passed.\n",
      "\n",
      "Checking file: Merged_Batches/batch_3.nc\n",
      "Variables: ['tp', 't2m', 'u10', 'sp', 'ssr']\n",
      "Dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 368, 'latitude': 751, 'longitude': 1201})\n",
      "Coordinates: Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 3kB 2024-07-01 ... 2024-09-30T18:...\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 6kB ...\n",
      "Time range: 2024-07-01T00:00:00.000000000 to 2024-09-30T18:00:00.000000000\n",
      "File check passed.\n",
      "\n",
      "Checking file: Merged_Batches/batch_4.nc\n",
      "Variables: ['tp', 't2m', 'u10', 'sp', 'ssr']\n",
      "Dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 201, 'latitude': 751, 'longitude': 1201})\n",
      "Coordinates: Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 2kB 2024-10-01 ... 2024-11-20\n",
      "  * latitude    (latitude) float64 6kB 85.0 84.9 84.8 84.7 ... 10.2 10.1 10.0\n",
      "  * longitude   (longitude) float64 10kB 190.0 190.1 190.2 ... 309.8 309.9 310.0\n",
      "    expver      (valid_time) <U4 3kB ...\n",
      "Time range: 2024-10-01T00:00:00.000000000 to 2024-11-20T00:00:00.000000000\n",
      "File check passed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    \"Merged_Batches/batch_1.nc\",\n",
    "    \"Merged_Batches/batch_2.nc\",\n",
    "    \"Merged_Batches/batch_3.nc\",\n",
    "    \"Merged_Batches/batch_4.nc\"\n",
    "]\n",
    "\n",
    "# 检查每个文件\n",
    "for file_path in file_paths:\n",
    "    print(f\"Checking file: {file_path}\")\n",
    "    try:\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        print(\"Variables:\", list(ds.data_vars.keys()))\n",
    "        print(\"Dimensions:\", ds.dims)\n",
    "        print(\"Coordinates:\", ds.coords)\n",
    "        print(f\"Time range: {ds['valid_time'].values[0]} to {ds['valid_time'].values[-1]}\")\n",
    "        print(\"File check passed.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading {file_path}: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有批次文件\n",
    "try:\n",
    "    ds_merged = xr.open_mfdataset(file_paths, combine=\"by_coords\")\n",
    "    print(\"Merged dataset dimensions:\", ds_merged.dims)\n",
    "    print(\"Merged dataset variables:\", list(ds_merged.data_vars.keys()))\n",
    "    print(f\"Merged time range: {ds_merged['valid_time'].values[0]} to {ds_merged['valid_time'].values[-1]}\")\n",
    "    ds_merged.to_netcdf(\"Merged_Batches/merged_dataset.nc\")\n",
    "    print(\"All batches successfully merged and saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging batches: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 1297, 'latitude': 751, 'longitude': 1201})\n",
      "Merged dataset variables: ['tp', 't2m', 'u10', 'sp', 'ssr']\n",
      "Merged time range: 2024-01-01T00:00:00.000000000 to 2024-11-20T00:00:00.000000000\n",
      "All batches successfully merged and saved.\n"
     ]
    }
   ],
   "source": [
    "# 合并所有批次文件\n",
    "try:\n",
    "    ds_merged = xr.open_mfdataset(file_paths, combine=\"by_coords\")\n",
    "    print(\"Merged dataset dimensions:\", ds_merged.dims)\n",
    "    print(\"Merged dataset variables:\", list(ds_merged.data_vars.keys()))\n",
    "    print(f\"Merged time range: {ds_merged['valid_time'].values[0]} to {ds_merged['valid_time'].values[-1]}\")\n",
    "    ds_merged.to_netcdf(\"Merged_Batches/merged_dataset.nc\")\n",
    "    print(\"All batches successfully merged and saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while merging batches: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while converting dataset to CSV: Unable to allocate 17.4 GiB for an array with shape (1297, 751, 1201) and data type <U4\n"
     ]
    }
   ],
   "source": [
    "# 将数据转换为 DataFrame 并保存为 CSV\n",
    "try:\n",
    "    df = ds_merged[\"tp\"].to_dataframe().reset_index()\n",
    "    print(\"Data size:\", df.shape)\n",
    "    print(f\"First few rows:\\n{df.head()}\")\n",
    "    df.to_csv(\"Merged_Batches/precipitation_data.csv\", index=False)\n",
    "    print(\"Data saved as precipitation_data.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while converting dataset to CSV: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
